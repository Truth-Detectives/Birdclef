{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1ba26d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T18:27:52.991015Z",
     "iopub.status.busy": "2025-05-15T18:27:52.990701Z",
     "iopub.status.idle": "2025-05-15T18:27:52.995470Z",
     "shell.execute_reply": "2025-05-15T18:27:52.994619Z"
    },
    "papermill": {
     "duration": 0.01043,
     "end_time": "2025-05-15T18:27:52.997298",
     "exception": false,
     "start_time": "2025-05-15T18:27:52.986868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install torchaudio\n",
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11813a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T18:27:53.003144Z",
     "iopub.status.busy": "2025-05-15T18:27:53.002837Z",
     "iopub.status.idle": "2025-05-15T18:28:02.613753Z",
     "shell.execute_reply": "2025-05-15T18:28:02.612758Z"
    },
    "papermill": {
     "duration": 9.61571,
     "end_time": "2025-05-15T18:28:02.615489",
     "exception": false,
     "start_time": "2025-05-15T18:27:52.999779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import dataclasses\n",
    "import torchaudio\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, Tuple, List\n",
    "from torchaudio.transforms import Resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc5c04b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T18:28:02.621421Z",
     "iopub.status.busy": "2025-05-15T18:28:02.620915Z",
     "iopub.status.idle": "2025-05-15T18:28:02.659030Z",
     "shell.execute_reply": "2025-05-15T18:28:02.658174Z"
    },
    "papermill": {
     "duration": 0.043091,
     "end_time": "2025-05-15T18:28:02.660852",
     "exception": false,
     "start_time": "2025-05-15T18:28:02.617761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_directory = \"/kaggle/input/birdclef-2025/test_soundscapes\"\n",
    "submission = \"/kaggle/input/birdclef-2025/sample_submission.csv\"\n",
    "train_file = \"/kaggle/input/birdclef-2025/train.csv\"\n",
    "taxonomy_file = \"/kaggle/input/birdclef-2025/taxonomy.csv\"\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class AudioParameters:\n",
    "    sample_rate: int = 32000\n",
    "    max_freq: int = 16000\n",
    "    min_freq: int = 20\n",
    "\n",
    "params = AudioParameters()\n",
    "\n",
    "submission_df = pd.read_csv(submission)\n",
    "index_to_class = submission_df.columns.drop(\"row_id\").tolist()\n",
    "class_to_index = {label: idx for idx, label in enumerate(index_to_class)}\n",
    "available_files = set(os.listdir(test_directory))\n",
    "submission_basenames = set(x.split(\"_\")[0] for x in submission_df[\"row_id\"])\n",
    "file_paths = [\n",
    "    os.path.join(test_directory, fname)\n",
    "    for fname in os.listdir(test_directory)\n",
    "    if Path(fname).stem in submission_basenames and fname.endswith(\".ogg\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cb1e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T18:28:02.666444Z",
     "iopub.status.busy": "2025-05-15T18:28:02.666105Z",
     "iopub.status.idle": "2025-05-15T18:28:02.985803Z",
     "shell.execute_reply": "2025-05-15T18:28:02.984875Z"
    },
    "papermill": {
     "duration": 0.324529,
     "end_time": "2025-05-15T18:28:02.987612",
     "exception": false,
     "start_time": "2025-05-15T18:28:02.663083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNmodel(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        temp = torch.zeros(1, 1, 128, 313)\n",
    "        with torch.no_grad():\n",
    "            x = self._forward_features(temp)\n",
    "        self.fc1 = nn.Linear(x.shape[1], num_classes)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self._forward_features(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNmodel(num_classes=len(index_to_class)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096204be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T18:28:02.995557Z",
     "iopub.status.busy": "2025-05-15T18:28:02.995184Z",
     "iopub.status.idle": "2025-05-15T18:28:03.063208Z",
     "shell.execute_reply": "2025-05-15T18:28:03.062162Z"
    },
    "papermill": {
     "duration": 0.073613,
     "end_time": "2025-05-15T18:28:03.065300",
     "exception": false,
     "start_time": "2025-05-15T18:28:02.991687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=params.sample_rate,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=128\n",
    ").to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, file_paths, device, chunk_size=5.0, sample_rate=32000):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    row_ids = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        if sr != sample_rate:\n",
    "            waveform = Resample(sr, sample_rate)(waveform)\n",
    "\n",
    "        total_samples = waveform.shape[1]\n",
    "        step = int(chunk_size * sample_rate)\n",
    "\n",
    "        for start in range(0, total_samples, step):\n",
    "            end = start + step\n",
    "            if end > total_samples:\n",
    "                break\n",
    "\n",
    "            chunk = waveform[:, start:end].to(device)\n",
    "            spectrogram = mel_transform(chunk)\n",
    "            spectrogram = spectrogram.log2().clamp(min=-10)\n",
    "            spectrogram = spectrogram.unsqueeze(0)\n",
    "\n",
    "            output = model(spectrogram)\n",
    "            prob = torch.sigmoid(output).cpu().numpy()\n",
    "\n",
    "            seconds = int(start / sample_rate)\n",
    "            row_id = f\"{Path(file_path).stem}_{seconds}\"\n",
    "            row_ids.append(row_id)\n",
    "            predictions.append(prob.squeeze())\n",
    "\n",
    "    return np.array(predictions), row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b3a89b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T18:28:03.072433Z",
     "iopub.status.busy": "2025-05-15T18:28:03.071550Z",
     "iopub.status.idle": "2025-05-15T18:28:03.135606Z",
     "shell.execute_reply": "2025-05-15T18:28:03.134348Z"
    },
    "papermill": {
     "duration": 0.069051,
     "end_time": "2025-05-15T18:28:03.137393",
     "exception": false,
     "start_time": "2025-05-15T18:28:03.068342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No test files found. Returning original sample submission.\n",
      "No predictions generated. Filling with zeros.\n",
      "Final submission shape: (3, 207)\n",
      "                  row_id  1139490  1192948  1194042  126247  1346504  134933  \\\n",
      "0   soundscape_8358733_5      0.0      0.0      0.0     0.0      0.0     0.0   \n",
      "1  soundscape_8358733_10      0.0      0.0      0.0     0.0      0.0     0.0   \n",
      "2  soundscape_8358733_15      0.0      0.0      0.0     0.0      0.0     0.0   \n",
      "\n",
      "   135045  1462711  1462737  ...  yebfly1  yebsee1  yecspi2  yectyr1  yehbla2  \\\n",
      "0     0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "1     0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "2     0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "   yehcar1  yelori1  yeofly1  yercac1  ywcpar  \n",
      "0      0.0      0.0      0.0      0.0     0.0  \n",
      "1      0.0      0.0      0.0      0.0     0.0  \n",
      "2      0.0      0.0      0.0      0.0     0.0  \n",
      "\n",
      "[3 rows x 207 columns]\n"
     ]
    }
   ],
   "source": [
    "submission_ids = []\n",
    "matrix = []\n",
    "\n",
    "if not file_paths:\n",
    "    print(\"No test files found. Returning original sample submission.\")\n",
    "else:\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        for audio_file in file_paths:\n",
    "            preds, ids = predict(model, [audio_file], device)\n",
    "            if ids:\n",
    "                submission_ids.extend(ids)\n",
    "                matrix.extend(preds)\n",
    "            gc.collect()\n",
    "\n",
    "if matrix:\n",
    "    pred_df = pd.DataFrame(\n",
    "        np.hstack([np.array(submission_ids).reshape(-1, 1), np.array(matrix).reshape(-1, len(index_to_class))]),\n",
    "        columns=[\"row_id\"] + index_to_class\n",
    "    )\n",
    "    pred_df[index_to_class] = pred_df[index_to_class].astype(float).round(6)\n",
    "\n",
    "    for i, row in pred_df.iterrows():\n",
    "        if row[\"row_id\"] in submission_df[\"row_id\"].values:\n",
    "            submission_df.loc[submission_df[\"row_id\"] == row[\"row_id\"], index_to_class] = row[index_to_class]\n",
    "else:\n",
    "    print(\"No predictions generated. Filling with zeros.\")\n",
    "    submission_df[index_to_class] = 0.0\n",
    "\n",
    "assert submission_df.shape == pd.read_csv(submission).shape, \"Submission shape mismatch\"\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Final submission shape:\", submission_df.shape)\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.687887,
   "end_time": "2025-05-15T18:28:06.295687",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-15T18:27:47.607800",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
